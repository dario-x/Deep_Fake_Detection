{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4c4635",
   "metadata": {
    "id": "3d4c4635"
   },
   "source": [
    "# Deep Fake Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aRV5QPaCS35T",
   "metadata": {
    "id": "aRV5QPaCS35T"
   },
   "source": [
    "## 0.1 Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "TtliBFv6S0ku",
   "metadata": {
    "id": "TtliBFv6S0ku"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import sys\n",
    "\n",
    "# for visuals\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "\n",
    "# handling files\n",
    "import zipfile\n",
    "import os\n",
    "import fnmatch\n",
    "import regex as re\n",
    "\n",
    "# dealing with images\n",
    "import skimage.color\n",
    "import skimage.exposure\n",
    "import skimage.io\n",
    "import skimage.util\n",
    "import skimage\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "from PIL import Image\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "#for cleaning up memory\n",
    "import gc\n",
    "\n",
    "#for deleting files\n",
    "import shutil\n",
    "\n",
    "#for shuffeling the data\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#for model visuals\n",
    "!pip install keras==2.8.*\n",
    "\n",
    "#for deep learning\n",
    "!pip install --upgrade tensorflow==2.8\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SimpleRNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.serialization import populate_deserializable_objects\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "#modifying images\n",
    "!pip install cvzone\n",
    "!pip install mediapipe\n",
    "import cvzone\n",
    "from cvzone.SelfiSegmentationModule import SelfiSegmentation\n",
    "import cv2\n",
    "segmentor = SelfiSegmentation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rLE7kLIcjLa2",
   "metadata": {
    "id": "rLE7kLIcjLa2"
   },
   "outputs": [],
   "source": [
    "# skip if not connected with GOOGLE COLAB\n",
    "\n",
    "#note I had to run the file on google colab since my processor was too weak\n",
    "#from google.colab import drive\n",
    "\n",
    "#connect to google drive\n",
    "#drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "#%cd gdrive/My\\ Drive/Colab_Notebooks/ML/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I9T8irhUWuKa",
   "metadata": {
    "id": "I9T8irhUWuKa"
   },
   "source": [
    "## Define Data Loading and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-Pq7CLxvRwjW",
   "metadata": {
    "id": "-Pq7CLxvRwjW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_color_image(path, imagesize):\n",
    "    \"\"\" simple function\n",
    "    to open an image from path as color image\"\"\"\n",
    "    # open file\n",
    "    image = cv2.imread(path)\n",
    "    # change color\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    # remove the background\n",
    "    image = segmentor.removeBG(image, (255, 255, 255), threshold=0.5)\n",
    "    # change contrast\n",
    "    # if we set alpha > 1 we will incrase the contrast\n",
    "    image = cv2.convertScaleAbs(image, alpha=1.2, beta=0)\n",
    "    # sharpen the imamge\n",
    "    image = cv2.filter2D(image, -1, np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]))\n",
    "    # change size\n",
    "    image = cv2.resize(image, imagesize)\n",
    "    # return normalized image\n",
    "    return image/255\n",
    "      \n",
    "def load_test_data(imagesize, home_path = './data/'):\n",
    "    \"\"\"\n",
    "    The main functionality to load images as numpy array given a datapath\n",
    "    Paramater imagesize is a 1x2 array indicating how big the\n",
    "    loaded image should be, bw meaning if black and white pictures should be loaded.\n",
    "    \"\"\"\n",
    "\n",
    "    testX = []\n",
    "    testY = []\n",
    "\n",
    "    for data_sub_set in ['test']:\n",
    "      for encoded_class, class_name in enumerate(['original', 'manipulated']):\n",
    "        for path, subdir, files in os.walk(home_path + data_sub_set + '/' + class_name + '/'):\n",
    "          for name in files:\n",
    "                loaded_image = load_color_image(os.path.join(path, name), imagesize)\n",
    "                testX.append(loaded_image)\n",
    "                testY.append(encoded_class)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    testX = np.array(testX, dtype = 'float32')\n",
    "    testY = np.array(testY, dtype = 'int32')\n",
    "\n",
    "    # returning scaled images\n",
    "    return testX, testY\n",
    "    \n",
    "imagesize=(180,180)\n",
    "def test(Model, Data_Path = './data/'):\n",
    "  \n",
    "    \"\"\" Function to load test data \n",
    "     make prediction on test data and to output the corresponding accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    testX, testY = load_test_data(imagesize, Data_Path)\n",
    "    testX, testY = shuffle(testX, testY)\n",
    "\n",
    "    X = testX\n",
    "    Y = testY\n",
    "    \n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Evaluation of Test  Set\")\n",
    "\n",
    "    #doing the prediction\n",
    "    Y_hat = Model.predict(testX)\n",
    "    #predYtest[Model_Name] = Y_hat\n",
    "\n",
    "    if \"keras.engine\" in str(type(Model)):\n",
    "      Y_hat = np.array(np.round_(Y_hat, decimals = 0, out = None), dtype=\"int32\")\n",
    "      Y_hat = np.array([x[0] for x in Y_hat.tolist()], dtype=\"int32\")\n",
    "    \n",
    "    #outputing accuracy, recall precision and AUC\n",
    "    accuracy = metrics.accuracy_score(Y, Y_hat)\n",
    "    recall = metrics.recall_score(Y, Y_hat)\n",
    "    precision = metrics.precision_score(Y, Y_hat)\n",
    "    AUC = metrics.roc_auc_score(Y, Y_hat)\n",
    "    print(\"Accuracy Score: {:.2f}\".format(accuracy))\n",
    "    print(\"Recall Score: {:.2f}\".format(recall))\n",
    "    print(\"Precision Score: {:.2f}\".format(precision))\n",
    "    print(\"AUC: {:.2f}\".format(AUC))\n",
    "        \n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    return accuracy, recall, precision, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XfHGGPjVyGT9",
   "metadata": {
    "id": "XfHGGPjVyGT9"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "IiEGO8GRtnHJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiEGO8GRtnHJ",
    "outputId": "0ecf18f2-eb5a-439d-f3da-f61ccd581910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "class RandomBrightnessChange(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 brightness_delta=[-0.1, 0.1], **kwargs):\n",
    "        super(RandomBrightnessChange, self).__init__(**kwargs)\n",
    "        self.brightness_delta = brightness_delta\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        if not training:\n",
    "            return images\n",
    "        \n",
    "        brightness = np.random.uniform(\n",
    "            self.brightness_delta[0], self.brightness_delta[1])\n",
    "        images = tf.image.adjust_brightness(images, brightness)\n",
    "        images = tf.clip_by_value(images, 0, 1)\n",
    "        return images\n",
    "\n",
    "        \n",
    "augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.03, input_shape = (imagesize[0], imagesize[1], 3)),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "    RandomBrightnessChange()\n",
    "    \n",
    "  ]\n",
    ")\n",
    "\n",
    "filter=16\n",
    "model = tf.keras.Sequential([\n",
    "      augmentation,\n",
    "      tf.keras.layers.Conv2D(filter, kernel_size=3, activation=\"tanh\"),\n",
    "      tf.keras.layers.Conv2D(filter, kernel_size=3), \n",
    "      tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2D(filter*2, kernel_size=4, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-10, l2=1e-9)),\n",
    "      tf.keras.layers.Conv2D(filter*2, kernel_size=4, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-10, l2=1e-9)),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2D(filter*2*2, kernel_size=5, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-10, l2=1e-9)),\n",
    "      tf.keras.layers.Conv2D(filter*2*2, kernel_size=5),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "      tf.keras.layers.Conv2D(filter*2*2*2*2, kernel_size=5, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-10, l2=1e-9)),\n",
    "      tf.keras.layers.Conv2D(filter*2*2*2*2, kernel_size=5, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-10, l2=1e-9)),\n",
    "      tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.GlobalAveragePooling2D(),\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-7, l2=1e-6)),\n",
    "      tf.keras.layers.Dropout(0.7),\n",
    "\n",
    "      tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00015, decay=0.00001), loss = \"binary_crossentropy\", metrics=['accuracy']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vngq1cWtyNdk",
   "metadata": {
    "id": "vngq1cWtyNdk"
   },
   "source": [
    "## Load Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9D0XgwxyQYg",
   "metadata": {
    "id": "f9D0XgwxyQYg"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CdhUtetAyKjc",
   "metadata": {
    "id": "CdhUtetAyKjc"
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bl5YrUqe1MbT",
   "metadata": {
    "id": "Bl5YrUqe1MbT"
   },
   "outputs": [],
   "source": [
    "test(model, \"./data/\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
