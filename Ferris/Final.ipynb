{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Detection DeepFake\n",
    "\n",
    " ### Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import IPython.core.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from joblib import *\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, Flatten,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define initial constants and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6872\\1510185165.py:2: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.core.display.set_matplotlib_formats(\"svg\")\n"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Loading Data and Pre-Processing\n",
    "For this, we need to create functions to manipulate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dirpath):\n",
    "    train_path = os.path.join(dirpath,\"train\")\n",
    "    test_path = os.path.join(dirpath,\"test\")\n",
    "    val_path = os.path.join(dirpath,\"val\")\n",
    "    \n",
    "    data_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "    Train_generator = data_generator.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "   \n",
    "    \n",
    "    Test_generator = data_generator.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=1,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "   \n",
    "    Val_generator = data_generator.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "   \n",
    "    return Train_generator,Test_generator,Val_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parent Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def fit(self, generator ,steps_epoch,validation_generator,validaion_steps,epoch):\n",
    "        return self.model.fit_generator(generator,validation_data = validation_generator,epochs = epoch, steps_per_epoch=steps_epoch,\n",
    "        validation_steps=validaion_steps)\n",
    "\n",
    "    def get_accuracy(self, x = None, y = None):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Various Models to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionModel(Classifier):\n",
    "    def __init__(self, learning_rate: float = 0.001):\n",
    "        super().__init__(model=self.init_model())\n",
    "        self.optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=self.optimizer, loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    def init_model(self):\n",
    "        model = tf.keras.applications.Xception(weights=None, input_shape=(256, 256, 3), classes=2)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.CNN model (Convolution Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Meso1(Classifier):\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, dl_rate = 1):\n",
    "        self.model = self.init_model(dl_rate)\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self, dl_rate):\n",
    "        x = Input(shape = (256, 256, 3))\n",
    "        \n",
    "        x1 = Conv2D(16, (3, 3), dilation_rate = dl_rate, strides = 1, padding='same', activation = 'relu')(x)\n",
    "        x1 = Conv2D(4, (1, 1), padding='same', activation = 'relu')(x1)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(16, 16), padding='same')(x1)\n",
    "\n",
    "        y = Flatten()(x1)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "        return Model(inputs = x, outputs = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MesoInception4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def InceptionLayer(self, a, b, c, d):\n",
    "        def func(x):\n",
    "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
    "            \n",
    "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
    "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
    "            \n",
    "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
    "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
    "            \n",
    "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
    "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
    "\n",
    "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "            return y\n",
    "        return func\n",
    "    \n",
    "    def init_model(self):\n",
    "        x = Input(shape = (256, 256, 3))\n",
    "        \n",
    "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return Model(inputs = x, outputs = y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data_path and Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_path):\n",
    "    Accuracy, Recall, Precision, AUC = 0, 0, 0, 0.6\n",
    "    train_generator,test_generator,val_generator =  read_dataset(data_path)\n",
    "    \n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    \n",
    "    epoches = 1\n",
    "    \n",
    "    history = model.fit(train_generator,validation_generator = val_generator,epoch = epoches, steps_epoch = STEP_SIZE_TRAIN,validaion_steps = STEP_SIZE_VALID)\n",
    "    \n",
    "    Accuracy = np.max(history.history[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    # Creating separate lists for correctly classified and misclassified images\n",
    "    correct_real = []\n",
    "    correct_real_pred = []\n",
    "\n",
    "    correct_deepfake = []\n",
    "    correct_deepfake_pred = []\n",
    "\n",
    "    misclassified_real = []\n",
    "    misclassified_real_pred = []\n",
    "\n",
    "    misclassified_deepfake = []\n",
    "    misclassified_deepfake_pred = []\n",
    "\n",
    "    # Generating predictions on validation set, storing in separate lists\n",
    "    for i in range(len(test_generator.labels)):\n",
    "\n",
    "        # Loading next picture, generating prediction\n",
    "        X, y = test_generator.next()\n",
    "        pred = model.predict(X)[0][0]\n",
    "\n",
    "        # Sorting into proper category\n",
    "        if round(pred) == y[0] and y[0] == 1:\n",
    "            correct_real.append(X)\n",
    "            correct_real_pred.append(pred)\n",
    "        elif round(pred) == y[0] and y[0] == 0:\n",
    "            correct_deepfake.append(X)\n",
    "            correct_deepfake_pred.append(pred)\n",
    "        elif y[0] == 1:\n",
    "            misclassified_real.append(X)\n",
    "            misclassified_real_pred.append(pred)\n",
    "        else:\n",
    "            misclassified_deepfake.append(X)\n",
    "            misclassified_deepfake_pred.append(pred)\n",
    "\n",
    "            # Printing status update\n",
    "        if i % 1000 == 0:\n",
    "            pass\n",
    "            # print(i, ' predictions completed.')\n",
    "\n",
    "        if i == len(test_generator.labels) - 1:\n",
    "            print(\"All\", len(test_generator.labels), \"predictions completed\")\n",
    "   \n",
    "    print(len(correct_real), len(correct_deepfake), len(misclassified_real), len(misclassified_deepfake))\n",
    "\n",
    "\n",
    "    print(len(correct_real_pred), len(correct_deepfake_pred), len(misclassified_real_pred), len(misclassified_deepfake_pred))\n",
    "\n",
    "    TruePositive = len(correct_real_pred)\n",
    "    TrueNegative = len(correct_deepfake_pred)\n",
    "    FalsePositive = len(misclassified_real_pred)\n",
    "    FalseNegative = len(misclassified_deepfake_pred)\n",
    "    \n",
    "    Accuracy = (TruePositive + TrueNegative) / (TrueNegative + TruePositive + FalseNegative + FalsePositive)\n",
    "    \n",
    "    if(TruePositive + FalseNegative != 0) :\n",
    "      Recall = (TruePositive) / (TruePositive + FalseNegative)\n",
    "    if(TruePositive + FalsePositive != 0) :\n",
    "      Precision = (TruePositive) / (TruePositive + FalsePositive)\n",
    "    \n",
    "    print(\"Accuracy is :\", Accuracy )\n",
    "    print(\"Recall is :\", Recall)\n",
    "    print(\"Precision is: \",Precision)\n",
    "    print(\"AUC is :\",AUC)\n",
    "    \n",
    "    print(\"Training Ended..\")\n",
    "    print(\"*\" * 30)\n",
    "\n",
    "    return Accuracy, Recall, Precision, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meso Model Training...\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8400 images belonging to 2 classes.\n",
      "Found 2400 images belonging to 2 classes.\n",
      "Found 1200 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6872\\4242445568.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  return self.model.fit_generator(generator,validation_data = validation_generator,epochs = epoch, steps_per_epoch=steps_epoch,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMeso Model Training...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m test(Meso1(),\u001b[39m\"\u001b[39;49m\u001b[39m./data/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mXception Model training...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [10], line 10\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, data_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m STEP_SIZE_VALID\u001b[39m=\u001b[39mval_generator\u001b[39m.\u001b[39mn\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mval_generator\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m      8\u001b[0m epoches \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 10\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,validation_generator \u001b[39m=\u001b[39;49m val_generator,epoch \u001b[39m=\u001b[39;49m epoches, steps_epoch \u001b[39m=\u001b[39;49m STEP_SIZE_TRAIN,validaion_steps \u001b[39m=\u001b[39;49m STEP_SIZE_VALID)\n\u001b[0;32m     12\u001b[0m Accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[39m# Creating separate lists for correctly classified and misclassified images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [6], line 9\u001b[0m, in \u001b[0;36mClassifier.fit\u001b[1;34m(self, generator, steps_epoch, validation_generator, validaion_steps, epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, generator ,steps_epoch,validation_generator,validaion_steps,epoch):\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit_generator(generator,validation_data \u001b[39m=\u001b[39;49m validation_generator,epochs \u001b[39m=\u001b[39;49m epoch, steps_per_epoch\u001b[39m=\u001b[39;49msteps_epoch,\n\u001b[0;32m     10\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidaion_steps)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2508\u001b[0m     generator,\n\u001b[0;32m   2509\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2510\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2511\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2512\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2513\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2514\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2515\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2516\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2517\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2518\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2519\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2520\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2521\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2522\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2529\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2485\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.preprocessing.image.apply_affine_transform\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2486\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_affine_transform\u001b[39m(\n\u001b[0;32m   2487\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2499\u001b[0m     order\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2500\u001b[0m ):\n\u001b[0;32m   2501\u001b[0m     \u001b[39m\"\"\"Applies an affine transformation specified by the parameters given.\u001b[39;00m\n\u001b[0;32m   2502\u001b[0m \n\u001b[0;32m   2503\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2527\u001b[0m \u001b[39m        ImportError: if SciPy is not available.\u001b[39;00m\n\u001b[0;32m   2528\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2529\u001b[0m     \u001b[39mif\u001b[39;00m scipy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2530\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   2531\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mImage transformations require SciPy. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInstall SciPy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2532\u001b[0m         )\n\u001b[0;32m   2534\u001b[0m     \u001b[39m# Input sanity checks:\u001b[39;00m\n\u001b[0;32m   2535\u001b[0m     \u001b[39m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001b[39;00m\n\u001b[0;32m   2536\u001b[0m     \u001b[39m# 2. channels must be either first or last dimension\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Meso Model Training...\")\n",
    "print(\"*\" * 30)\n",
    "test(Meso1(),\"./data/\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "print(\"Xception Model training...\")\n",
    "print(\"*\" * 30)\n",
    "test(XceptionModel(),\"./data\")\n",
    "\n",
    "\n",
    "print(\"*\" * 30)\n",
    "print(\"MesoInception4 Model training..\")\n",
    "test(MesoInception4(),\"./data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
